# 油气人工智能基础<br />
---
这周人工智能课留了一个作业，其中的一个内容就是把对抗生成网络的原理弄懂，就借着这次作业开始精读板块。<br />
对抗生成网络(Generative Adversarial Nets, GAN)广泛应用于图像生成，图片风格融合，换脸等领域，我想以后大概率不会涉及这个领域，权当是“万事开头难”吧。<br />
作为一个科研领域的小白，所阅读的文献量是很少的，但大概也有一套自己的方法：对于这种肯定要精读的论文就按照顺序读完，而对于一篇新的论文是先看摘要和结论，为了以后的统一，就按照摘要—结论—其他这样的顺序来写了。说了这么多，那开始论文精度的第一篇——GAN。<br />
### 摘要(Abstract)
我们通过相互对抗的过程(adversarial process)提出了一个新的估计生成模型(estimating generative models)**框架(framework)** 。要同时训练两个模型：  **生成模型(generative model)** $G$ 和 **判别模型(descriminative model)** $D$ 。其中生成模型 $G$ 是要 **捕捉训练数据的分布** ， 判别模型 $D$ 是 **估计一个样本是来自训练数据集而不是生成模型的概率**。对 $G$的训练过程是 **最大化$D$ 犯错误的概率**。对于任何$G$ 和 $D$的函数空间中，都存在唯一一个解，使得 $G$可以复原训练数据的分布而 $D$恒等于 $\frac{1}{2}$ (在理论推导中会解释)。若$G$ 和 $D$都是多层感知机(multilayer perceptron, MLP),则系统可以通过反向传播(backpropagation)来训练,整个过程不需要任何马尔科夫链。
>核心是两个模型$G$和$D$，只要弄明白两个模型代表的含义，就能知道这个算法的思想，而后就转化为一个数学层面的最优化问题。
### 简介(Introduction)
首先作者给深度学习下了一个定义：**深度学习的目的是发现丰富的、有层次的模型来表示在人工智能应用中遇到的各种数据的概率分布。** 作者提到目前为止，深度学习通过反向传播与丢弃算法在(backpropagation and dropout algorithms) **判别模型**上有着惊人的成功，而对于深度**生成模型**逐渐失去了影响，由于通过极大似然估计来判别数据集的分布参数太过复杂。<br />
接下来作者用一个很形象的例子来说明对抗网络模型是在干什么：在所提出的对抗网络框架中，生成模型 $G$ 与对手——判别模型 $D$ 进行竞赛，$D$ 用来确定样本是来自$G$还是来自训练数据。生成模型 $G$可以被认为类似于一组造假者(counterfeiters)，试图生产假币并在未经检测的情况下使用，而辨别模型$D$则类似于警察(police)，试图检测假币。在这个游戏中的竞争促使两队改进他们的方法，直到仿冒品与真品难以区分。<br />
该框架可以为多种模型和优化算法生成特定的训练算法。在本文中，我们探讨了生成模型通过将**随机噪声通过多层感知器来生成样本**的特殊情况，而判别模型也是多层感知机。在这种情况下，我们可以仅使用非常成功的反向传播和丢弃算法来训练这两个模型，并仅使用正向传播从生成模型中采样,不需要统计推断或马尔可夫链。
### 对抗网络(Adversarial nets)
对抗生成模型最简单的应用是当生成模型和判别模型都是多层感知机。为了通过训练数据 $\pmb{x}$ 来学习生成器(generator)的分布 $p_g$, 我们输入噪声随机变量 $p_z(z)$, 用 $G(z;\theta_g)$ 来 代表到训练数据集样本空间的映射(mapping)，其中 $G(z;\theta_g)$ 是一个代表参数为 $\theta_g$ 的多层感知机的可微函数。$D(x;\theta_d)$ 同样是一个多层感知机函数，其**代表数据 $\pmb{x}$   来自训练样本而不是生成器的概率**。于是我们可以定义目标函数：<br />
对于警察，若 $\pmb{x}$ 来自训练样本 $p_d$ ，则 $D(x)$应增大，进而 $logD(x)$ 增大；若 $\pmb{x}$ 来自生成器 $p_g$ ，则 $1-D(G(z))$ 应增大，进而 $log(1-D(G(z)))$ 增大。由此，判别模型 $D$ 的目标函数为：<br />

$$
\underset{D}{max}E_{x\to p_{data}}(logD(x))+E_{z\to p_{g}}(log(1-D(G(z))))
$$

>数学期望 $E$ :<br />
>1.离散随机变量：$E(x)=\sum_{i=1}^Nx_ip_i$, 其中$p_i$是抽取到 $x_i$的概率；<br />
>2.连续随机变量：$E(x)=\int_{-\infty}^\infty xf(x)$, 其中$f(x)$是 $x$的概率密度函数。<vbr />

对于造假者，若$\pmb{x}$ 来自训练样本$p_d$，则 $D(x)$应增大，进而 $1-D(x)$减小，进而 $log(1-D(G(z)))$减小。由此，生成模型$G$的目标函数为：<br />
$$
\underset{G}{min}E_{z\to p_{g}}(log(1-D(G(z))))
$$
进而得到整个模型的目标函数$V(D,G)$:<br />
$$
V(D,G)=\underset{G}{min}\underset{D}{max}E_{x\to p_{data(x)}}(logD(x))+E_{z\to p_{g(z)}}(log(1-D(G(z))))
$$
### 理论推导(Theoretical Results)
当噪声随机变量$z$ ~$p_z$ 时，生成模型 $G$ 通过样本分布 $G(z) $**隐式地**定义了一个概率分布 $p_g$。下图可以很好的理解整个训练过程：<br />
通过同时更新辨别模型分布（$D$，蓝色虚线）来训练GAN，使得其区分来自训练数据分布的样本$p_x$（黑色虚线）和来自生成模型分布$p_g(G)$的样本（绿色，实线）。下面的横线是噪声随机变量$z$的采样区域，图示是均匀采样。上面的横线是$x$域的一部分。而箭头代表了映射$\pmb{x}=G(z)$是如何迫使非均匀分布转换为训练样本。<br />
(a)对于如图所示的对抗：$p_g$与$p_{data}$相似，同时判别模型$D$是部分准确的.<br />
(b)通过对判别模型$D$的训练，其逐渐的可以区分生成数据分布和训练数据分布，其最优值收敛到$D^*=\frac{p_{data}(x)}{p_{data}(x)+p_{g}(x)}.$<br />
(c)通过更新迭代生成模型$G$,其生成的数据与训练样本更加接近.<br />
(d)通过几次的迭代，最终$G$和$D$将达到$p_g=p_{data}$而无法在进行提升,同时判别模型$D$满足$D(x)=\frac{1}{2}$而无法进行区分.<br />
数学优化模型推导：<br />
对于求解$\underset{D}{max}$我们首先固定参数$G$,则此时$V(G,D)$中的期望可以转化为积分，即：<br />
$$
V(D,G)=\int_xp_{data}(x)log(D(x))dx+\int_zp_z(z)log(1-D(g(z)))dz = \int_xp_{data}(x)log(D(x))+ p_g(x)log(1-D(x))dx
$$
我们想求$V(D,G)$的最大值，则令其导数等于0:<br />
$$
\frac{\partial}{\partial D}(\underset{D}{max}V(D,G))= \frac{\partial}{\partial D}\int_xp_{data}(x)log(D(x))+ p_g(x)log(1-D(x))dx=\int\frac{\partial}{\partial D}(p_{data}(x)log(D(x))+ p_g(x)log(1-D(x))dx)=\int(p_{data}\frac{1}{D}-\frac{p_g}{1-D})dx=0
$$
由此得到$D$的最优值$D^*$：<br />
$$
D^*=\frac{p_{data}}{p_{data}+p_g}
$$
此时，我们将$D$的最优值$D^*$带入$V(G,D)$中继续求解目标函数值：<br />
$$
C(G)=\underset{G}{min}V(G,D^*)=\underset{G}{min}E_{x\to p_{data}}(log\frac{p_{data}(x)}{p_{data}(x)+p_g(x)})+E_{z\to p_{g(x)}}(log\frac{p_{g}(x)}{p_{data}(x)+p_g(x)})
$$
这里用到了一个信息论中的KL散度，我简单看了一下，大概是一个概率的描述定义，这里利用KL散度进行求解：<br />
$$
\underset{G}{min}E_{x\to p_{data}}(log\frac{p_{data}(x)}{p_{data}(x)+p_g(x)})+E_{z\to p_{g(x)}}(log\frac{p_{g}(x)}{p_{data}(x)+p_g(x)})=\underset{G}{min}E_{x\to p_{data}}(log\frac{p_{data}(x)}{(p_{data}(x)+p_g(x))/2}\frac{1}{2})+E_{z\to p_{g(x)}}(log\frac{p_{g}(x)}{(p_{data}(x)+p_g(x))/2}\frac{1}{2})
$$
>这里将分母除以2的目的是由于$p_{data}(x)+p_g(x)$的范围是[0,2]，不属于随机变量，因此将其范围压缩到[0,1]，只有分子分母均为随机变量才可以利用KL散度求解.
上式转化为：<br />
$$
\underset{G}{min}KL(p_{data}||\frac{p_{data}(x)+p_g(x)}{2})+KL(p_{g}||\frac{p_{data}(x)+p_g(x)}{2})-log4\geq-log4
$$
易知当$p_{data}=\frac{p_{data}+p_g}{2}=p_g$ 时等号成立，由此，$V(G,D)$的最优解为：$p_g^*=p_{data}$，同时$D_G^*=\frac{1}{2}$.
### 评价与结论(Conclusions)
作者在第六段说明了模型目前存在的优缺点，作者当时提出来时其实模型效果并不好，但是基本可以达到效果，即这个模型提出的是“初号机”，目前通过很多研究者的改良，GAN模型已经可以达到很好的效果了，在此简单的写一下文章中提出的优缺点：<br />
缺点是不能显式的将$p_g(x)$表示出来（但我寻思他的创新点不就是绕过了显式表达吗...）;而优点就是他说了很多遍的不依赖于马尔科夫链。<br />
最后，作者给出了模型的实验效果，可以看到除了生成数字其余的效果并不是很好。<br />
以上就是生成对抗神经网络论文精度的全部内容，因为目前研一还有很多的课程，所以这个板块可能更新的比较慢，但还是加油！
